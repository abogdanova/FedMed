{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqrD7Yzlmlsk"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "2k8X1C1nmpKv"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32xflLc4NTx-"
   },
   "source": [
    "# Custom Federated Algorithms, Part 2: Implementing Federated Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtATV6DlqPs0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.4.0/docs/tutorials/custom_federated_algorithms_2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.4.0/docs/tutorials/custom_federated_algorithms_2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_igJ2sfaNWS8"
   },
   "source": [
    "This tutorial is the second part of a two-part series that demonstrates how to\n",
    "implement custom types of federated algorithms in TFF using the\n",
    "[Federated Core (FC)](../federated_core.md), which serves as a foundation for\n",
    "the [Federated Learning (FL)](../federated_learning.md) layer (`tff.learning`).\n",
    "\n",
    "We encourage you to first read the\n",
    "[first part of this series](custom_federated_algorithms_1.ipynb), which\n",
    "introduce some of the key concepts and programming abstractions used here.\n",
    "\n",
    "This second part of the series uses the mechanisms introduced in the first part\n",
    "to implement a simple version of federated training and evaluation algorithms.\n",
    "\n",
    "We encourage you to review the\n",
    "[image classification](federated_learning_for_image_classification.ipynb) and\n",
    "[text generation](federated_learning_for_text_generation.ipynb) tutorials for a\n",
    "higher-level and more gentle introduction to TFF's Federated Learning APIs, as\n",
    "they will help you put the concepts we describe here in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuJuLEh2TfZG"
   },
   "source": [
    "## Before we start\n",
    "\n",
    "Before we start, try to run the following \"Hello World\" example to make sure\n",
    "your environment is correctly setup. If it doesn't work, please refer to the\n",
    "[Installation](../install.md) guide for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rB1ovcX1mBxQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_federated in /anaconda3/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: enum34~=1.1 in /anaconda3/lib/python3.7/site-packages (from tensorflow_federated) (1.1.6)\n",
      "Requirement already satisfied: numpy~=1.14 in /anaconda3/lib/python3.7/site-packages (from tensorflow_federated) (1.16.4)\n",
      "Requirement already satisfied: h5py~=2.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow_federated) (2.8.0)\n",
      "Requirement already satisfied: six~=1.10 in /anaconda3/lib/python3.7/site-packages (from tensorflow_federated) (1.12.0)\n",
      "Requirement already satisfied: tensorflow~=1.13 in /anaconda3/lib/python3.7/site-packages (from tensorflow_federated) (1.13.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.0.9)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.19.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.13.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.13.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (0.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (0.31.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.0.7)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (3.7.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow~=1.13->tensorflow_federated) (1.1.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow~=1.13->tensorflow_federated) (3.0.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow~=1.13->tensorflow_federated) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow~=1.13->tensorflow_federated) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow~=1.13->tensorflow_federated) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "# NOTE: If you are running a Jupyter notebook, and installing a locally built\n",
    "# pip package, you may need to edit the following to point to the '.whl' file\n",
    "# on your local filesystem.\n",
    "\n",
    "#!pip install tensorflow_federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-skNC6aovM46"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data\n",
    "from tensorflow_federated import python as tff\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1550886524193,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "zzXwGnZamIMM",
    "outputId": "9febf2e4-6cb9-44c5-b665-629acef0f2f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, World!'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tff.federated_computation\n",
    "def hello_world():\n",
    "  return 'Hello, World!'\n",
    "\n",
    "\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu5Gd8D6W33s"
   },
   "source": [
    "## Implementing Federated Averaging\n",
    "\n",
    "As in\n",
    "[Federated Learning for Image Classification](federated_learning_for_image_classification.md),\n",
    "we are going to use the MNIST example, but since this is intended as a low-level\n",
    "tutorial, we are going to bypass the Keras API and `tff.simulation`, write raw\n",
    "model code, and construct a federated data set from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6qCjef350c_"
   },
   "source": [
    "\n",
    "### Preparing federated data sets\n",
    "\n",
    "For the sake of a demonstration, we're going to simulate a scenario in which we\n",
    "have data from 10 users, and each of the users contributes knowledge how to\n",
    "recognize a different digit. This is about as\n",
    "non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables)\n",
    "as it gets.\n",
    "\n",
    "First, let's load the standard MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uThZM4Ds-KDQ"
   },
   "outputs": [],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "cifar_train, cifar_test = tf.keras.datasets.cifar10.load_data()\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "cifar_class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar_test = (cifar_test[0], tf.keras.utils.to_categorical(cifar_test[1]))\n",
    "# cifar_train = (cifar_train[0], tf.keras.utils.to_categorical(cifar_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1550886524725,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "PkJc5rHA2no_",
    "outputId": "baa6de95-5e62-4f4f-a5ad-5a82358a2d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 32, 32, 3), (50000, 1)]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in cifar_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000, 32, 32, 3), (10000, 1)]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in cifar_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFET4BKJFbkP"
   },
   "source": [
    "The data comes as Numpy arrays, one with images and another with digit labels, both\n",
    "with the first dimension going over the individual examples. Let's write a\n",
    "helper function that formats it in a way compatible with how we feed federated\n",
    "sequences into TFF computations, i.e., as a list of lists - the outer list\n",
    "ranging over the users (digits), the inner ones ranging over batches of data in\n",
    "each client's sequence. As is customary, we will structure each batch as a pair\n",
    "of tensors named `x` and `y`, each with the leading batch dimension. While at\n",
    "it, we'll also flatten each image into a 784-element vector and rescale the\n",
    "pixels in it into the `0..1` range, so that we don't have to clutter the model\n",
    "logic with data conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTaTLiq5GNqy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:59: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "NUM_EXAMPLES_PER_USER = 2000\n",
    "BATCH_SIZE = 32\n",
    "USERS = 5\n",
    "NUM_EPOCHS = 2\n",
    "CLASSES = 10\n",
    "\n",
    "\n",
    "# def get_indices_unbalanced(y):\n",
    "#     # split dataset into arrays of each class label\n",
    "#     indices_array = []\n",
    "#     for c in range(CLASSES):\n",
    "#         indices_array.append([i for i, d in enumerate(y) if d == c])\n",
    "#     class_shares = CLASSES // min(CLASSES, USERS)\n",
    "#     user_indices = []\n",
    "#     for u in range(USERS):\n",
    "#         user_indices.append(\n",
    "#             np.array(\n",
    "#                 [indices_array.pop(0)[:NUM_EXAMPLES_PER_USER//class_shares] for j in range(class_shares)])\n",
    "#             .flatten())\n",
    "#     return user_indices\n",
    "\n",
    "def get_indices_unbalanced(y):\n",
    "    # split dataset into arrays of each class label\n",
    "    indices_array = []\n",
    "    for c in range(CLASSES):\n",
    "        indices_array.append([i for i, d in enumerate(y) if d == c])\n",
    "    # each user will have 2 classes excluded from their data sets, thus 250 examples * remaining 8 classes\n",
    "    class_shares = 250\n",
    "    # store indices for future use\n",
    "    user_indices = []\n",
    "    # auxilary index array to pop out pairs of classes missing at each user\n",
    "    class_index = list(range(CLASSES))\n",
    "    for u in range(USERS):\n",
    "        columns_out = [class_index.pop(0) for i in range(2)]\n",
    "        selected_columns = set(range(CLASSES)) - set(columns_out)\n",
    "        starting_index = u*class_shares\n",
    "        user_indices.append(\n",
    "            np.array(indices_array)[list(selected_columns)].T[starting_index:starting_index + class_shares]\n",
    "            .flatten())\n",
    "    return user_indices\n",
    "\n",
    "def get_indices_even(y):\n",
    "    # split dataset into arrays of each class label\n",
    "    indices_array = []\n",
    "    for c in range(CLASSES):\n",
    "        indices_array.append([i for i, d in enumerate(y) if d == c])\n",
    "    user_indices = []\n",
    "    class_shares = NUM_EXAMPLES_PER_USER // CLASSES\n",
    "    \n",
    "    # take even shares of each class for every user\n",
    "    for u in range(USERS):\n",
    "        starting_index = u*class_shares\n",
    "        user_indices.append(np.array(indices_array).T[starting_index:starting_index + class_shares].flatten())   \n",
    "    return user_indices\n",
    "\n",
    "def get_non_distributed(source):\n",
    "    indices = np.concatenate(get_indices_even(source[1]))\n",
    "    y = tf.keras.utils.to_categorical(np.array(source[1][[indices]], dtype=np.int32))\n",
    "    X = np.array(source[0][[indices]], dtype=np.float32) / 255.0\n",
    "    return X, y\n",
    "    \n",
    "def get_distributed(source, u, distribution):\n",
    "    if distribution == 'iid':\n",
    "        indices = get_indices_even(source[1])[u]\n",
    "    else:\n",
    "        indices = get_indices_unbalanced(source[1])[u]\n",
    "    output_sequence = []\n",
    "    for repeat in range(NUM_EPOCHS):\n",
    "        for i in range(0, len(indices), BATCH_SIZE):\n",
    "            batch_samples = indices[i:i + BATCH_SIZE]\n",
    "            output_sequence.append({\n",
    "                'x': np.array([source[0][b] / 255.0 for b in batch_samples], dtype=np.float32),\n",
    "                'y': tf.keras.utils.to_categorical(np.array([source[1][b] for b in batch_samples], dtype=np.int32))})\n",
    "    return output_sequence\n",
    "\n",
    "\n",
    "federated_train_data = [get_distributed(cifar_train, u, 'non-iid') for u in range(USERS)]\n",
    "federated_test_data = [get_distributed(cifar_test, u, 'non-iid') for u in range(USERS)]\n",
    "\n",
    "(X, y) = get_non_distributed(cifar_train)\n",
    "(X_test, y_test) = get_non_distributed(cifar_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(federated_train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = len(federated_train_data[0][0]['x'][1])\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = federated_train_data[1][-2]\n",
    "sample_batch['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpNdBimWaMHD"
   },
   "source": [
    "As a quick sanity check, let's look at the `Y` tensor in the last batch of data\n",
    "contributed by the fifth client (the one corresponding to the digit `5`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xgvcwv7Obhat"
   },
   "source": [
    "Just to be sure, let's also look at the image corresponding to the last element of that batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1550886527273,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "cI4aat1za525",
    "outputId": "e516287a-fbee-49c9-f861-4691e5caf283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "print(cifar_class_labels[federated_train_data[4][5]['y'][-5][0]])\n",
    "plt.imshow(federated_train_data[4][5]['x'][-5].reshape(32, 32, 3))\n",
    "#plt.imshow(cifar_train[0][4])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "CHANNELS = 3\n",
    "\n",
    "from tensorflow.python.keras.optimizer_v2 import gradient_descent\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_compiled_keras_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"tanh\",\n",
    "            padding=\"same\",\n",
    "            input_shape=(WIDTH, HEIGHT, CHANNELS)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"tanh\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(128, activation=\"tanh\"),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "    \n",
    "    def loss_fn(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
    "        y_true, y_pred))\n",
    "    \n",
    "    model.compile(\n",
    "      loss=tf.keras.losses.categorical_crossentropy,\n",
    "      optimizer=\"adam\",\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-federated keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_federated_model = create_compiled_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "10000/10000 [==============================] - 25s 3ms/sample - loss: 1.6435 - categorical_accuracy: 0.4125 - val_loss: 1.4474 - val_categorical_accuracy: 0.4735\n",
      "Epoch 2/12\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 1.2976 - categorical_accuracy: 0.5413 - val_loss: 1.2611 - val_categorical_accuracy: 0.5547\n",
      "Epoch 3/12\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 1.1086 - categorical_accuracy: 0.6126 - val_loss: 1.2279 - val_categorical_accuracy: 0.5650\n",
      "Epoch 4/12\n",
      "10000/10000 [==============================] - 18s 2ms/sample - loss: 0.9733 - categorical_accuracy: 0.6610 - val_loss: 1.2456 - val_categorical_accuracy: 0.5785\n",
      "Epoch 5/12\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 0.8426 - categorical_accuracy: 0.7058 - val_loss: 1.2644 - val_categorical_accuracy: 0.5728\n",
      "Epoch 6/12\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 0.7135 - categorical_accuracy: 0.7566 - val_loss: 1.2610 - val_categorical_accuracy: 0.5845\n",
      "Epoch 7/12\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 0.5815 - categorical_accuracy: 0.8037 - val_loss: 1.2990 - val_categorical_accuracy: 0.5864\n",
      "Epoch 8/12\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 0.4380 - categorical_accuracy: 0.8597 - val_loss: 1.4316 - val_categorical_accuracy: 0.5772\n",
      "Epoch 9/12\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 0.3198 - categorical_accuracy: 0.9050 - val_loss: 1.4353 - val_categorical_accuracy: 0.5902\n",
      "Epoch 10/12\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 0.2058 - categorical_accuracy: 0.9477 - val_loss: 1.4991 - val_categorical_accuracy: 0.5952\n",
      "Epoch 11/12\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 0.1122 - categorical_accuracy: 0.9811 - val_loss: 1.5508 - val_categorical_accuracy: 0.5929\n",
      "Epoch 12/12\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 0.0633 - categorical_accuracy: 0.9936 - val_loss: 1.6288 - val_categorical_accuracy: 0.5955\n"
     ]
    }
   ],
   "source": [
    "history_callback = non_federated_model.fit(X, y, validation_data=(X_test, y_test), batch_size=32, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6563694650650025,\n",
       " 1.3007290199279786,\n",
       " 1.1194022260665895,\n",
       " 0.9801722335815429,\n",
       " 0.8453258259773254,\n",
       " 0.7207920631408692,\n",
       " 0.569933446264267,\n",
       " 0.42374285163879394,\n",
       " 0.30032064225673677,\n",
       " 0.19598041729927063,\n",
       " 0.11359974697828293,\n",
       " 0.0627660088956356]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = history_callback.history['loss']\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_federated_model.save(\"non_federated_cifar10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('Log/Exp2/'+ datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")+'.txt', 'w') as log:\n",
    "        print(\"Cifar10, Non-federated, IDD, minibatch_size: 32\", file=log)\n",
    "        print(\"Train Loss: {}\".format(history_callback.history[\"loss\"]), file=log)\n",
    "        print(\"Test Accuracy: {}\".format(history_callback.history[\"val_sparse_categorical_accuracy\"]), file=log)\n",
    "                \n",
    "except IOError:\n",
    "    print('File Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    keras_model = create_compiled_keras_model()\n",
    "    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=<categorical_accuracy=0.44825,loss=1.5218289>\n",
      "test accuracy: 0.4037500023841858\n"
     ]
    }
   ],
   "source": [
    "# One round / one user test\n",
    "state = iterative_process.initialize()\n",
    "state, metrics = iterative_process.next(state, federated_train_data[0:1])\n",
    "test_metrics = evaluation(state.model, federated_test_data)\n",
    "print('round  1, metrics={}'.format(metrics))\n",
    "print('test accuracy: {}'.format(test_metrics.categorical_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=<sparse_categorical_accuracy=0.441375,loss=1.5422242>\n",
      "round  1, metrics=<sparse_categorical_accuracy=0.542,loss=1.2852292>\n",
      "round  2, metrics=<sparse_categorical_accuracy=0.61525,loss=1.0956982>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.608125,loss=1.1381797>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.671125,loss=0.94584024>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.7105,loss=0.83895534>\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "state = iterative_process.initialize()\n",
    "fd_test_accuracy = []\n",
    "fd_train_loss = []\n",
    "for round_num in range(6):\n",
    "    selected = np.random.choice(5, 2, replace=False)\n",
    "    state, metrics = iterative_process.next(state, list(np.array(federated_train_data)[selected]))\n",
    "    test_metrics = evaluation(state.model, federated_test_data)\n",
    "    fd_train_loss.append(metrics[1])\n",
    "    fd_test_accuracy.append(test_metrics.sparse_categorical_accuracy)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.494875, 0.55725, 0.576375, 0.579625]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 504us/sample - loss: 2.0773 - sparse_categorical_accuracy: 0.6001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0773194374084474, 0.6001]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_federated_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 360us/sample - loss: 1.2888 - sparse_categorical_accuracy: 0.5730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2887664936065675, 0.573]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_federated_model.set_weights(tff.learning.keras_weights_from_tff_weights(state.model))\n",
    "non_federated_model.save('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = np.random.choice(5, 4, replace=False)\n",
    "len(list(np.array(federated_train_data)[selected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('Log/Exp5/niiE2C2.txt', 'w') as log:\n",
    "        print(\"Cifar10, Federated E2C2, non-IDD, minibatch_size: 32\", file=log)\n",
    "        print(\"Train Loss: {}\".format(fd_train_loss), file=log)\n",
    "        print(\"Test Accuracy: {}\".format(fd_test_accuracy), file=log)\n",
    "                \n",
    "except IOError:\n",
    "    print('File Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Attach (MIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "CHANNELS = 3\n",
    "SHADOW_DATASET_SIZE = 1000\n",
    "ATTACK_TEST_DATASET_SIZE = 4000\n",
    "\n",
    "\n",
    "target_epochs = 12\n",
    "attack_epochs = 12\n",
    "num_shadows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_model_fn():\n",
    "    \"\"\"Attack model that takes target model predictions and predicts membership.\n",
    "\n",
    "    Following the original paper, this attack model is specific to the class of the input.\n",
    "    AttachModelBundle creates multiple instances of this model for each class.\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(128, activation=\"relu\", input_shape=(NUM_CLASSES,)))\n",
    "\n",
    "    model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:loss_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-383-4b21ffbcaea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-383-4b21ffbcaea2>\u001b[0m in \u001b[0;36mtarget_model_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load target models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtarget_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'non_federated_cifar10.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#model = load_model('target_cifar10.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m           sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mget_loss_function\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    592\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    583\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError('Unknown ' + printable_module_name + ':' +\n\u001b[0;32m--> 212\u001b[0;31m                          function_name)\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:loss_fn"
     ]
    }
   ],
   "source": [
    "# Load target models\n",
    "def target_model_fn():\n",
    "    model = load_model('non_federated_cifar10.h5')\n",
    "    #model = load_model('target_cifar10.h5')\n",
    "    return model\n",
    "\n",
    "target_model = target_model_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3) (5000, 32, 32, 3)\n",
      "Training the shadow models...\n",
      "Train on 1000 samples, validate on 5000 samples\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[1], expected a dimension of 1, got 10\n\t [[{{node metrics_37/sparse_categorical_accuracy/Squeeze}}]] [Op:StatefulPartitionedCall]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-a9a525277add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattacker_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattacker_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/mia/estimators.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, verbose, fit_kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDoing\u001b[0m \u001b[0mso\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mdecrease\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/mia/estimators.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, verbose, pseudo, fit_kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Train the shadow model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mshadow_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mshadow_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShadowModelBundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_ID_FMT\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3164\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3166\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3167\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3168\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got two values for keyword '{}'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munused_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keyword arguments {} unknown.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_proto_serialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m           executor_type=function_call_options.executor_type)\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       outputs = gen_functional_ops.stateful_partitioned_call(\n\u001b[1;32m   1082\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m           executor_type=executor_type)\n\u001b[0m\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[0;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[1], expected a dimension of 1, got 10\n\t [[{{node metrics_37/sparse_categorical_accuracy/Squeeze}}]] [Op:StatefulPartitionedCall]"
     ]
    }
   ],
   "source": [
    "# Train the shadow models.\n",
    "smb = ShadowModelBundle(\n",
    "    target_model_fn,\n",
    "    shadow_dataset_size=SHADOW_DATASET_SIZE,\n",
    "    num_models=num_shadows\n",
    ")\n",
    "\n",
    "# Using cifar10 test set to train shadow models\n",
    "attacker_X_train, attacker_X_test, attacker_y_train, attacker_y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5)\n",
    "\n",
    "print(attacker_X_train.shape, attacker_X_test.shape)\n",
    "\n",
    "print(\"Training the shadow models...\")\n",
    "X_shadow, y_shadow = smb.fit_transform(\n",
    "    attacker_X_train,\n",
    "    attacker_y_train,\n",
    "    fit_kwargs=dict(\n",
    "        epochs=target_epochs,\n",
    "        verbose=True,\n",
    "        validation_data=(attacker_X_test, attacker_y_test)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the attack models...\n",
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 2s 102us/sample - loss: 0.5403 - acc: 0.7143\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.4163 - acc: 0.8039\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 1s 58us/sample - loss: 0.3901 - acc: 0.8239\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 1s 58us/sample - loss: 0.3856 - acc: 0.8269\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 1s 69us/sample - loss: 0.3820 - acc: 0.8309\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 1s 58us/sample - loss: 0.3796 - acc: 0.8340\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 1s 59us/sample - loss: 0.3807 - acc: 0.8326\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.3789 - acc: 0.8334\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.3782 - acc: 0.8328\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 1s 68us/sample - loss: 0.3776 - acc: 0.8334\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 1s 67us/sample - loss: 0.3759 - acc: 0.8343\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 1s 62us/sample - loss: 0.3753 - acc: 0.8351\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-5a8ab22645ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the attack models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the attack models...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m amb.fit(X_shadow, y_shadow, fit_kwargs=dict(epochs=attack_epochs, verbose=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/mia/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, verbose, fit_kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mfit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n",
    "amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Fit the attack models.\n",
    "print(\"Training the attack models...\")\n",
    "amb.fit(X_shadow, y_shadow, fit_kwargs=dict(epochs=attack_epochs, verbose=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the success of the attack.\n",
    "\n",
    "# Prepare examples that were in the training, and out of the training.\n",
    "data_in = X_train[:ATTACK_TEST_DATASET_SIZE], y_train[:ATTACK_TEST_DATASET_SIZE]\n",
    "data_out = attacker_X_test[:ATTACK_TEST_DATASET_SIZE], attacker_y_test[:ATTACK_TEST_DATASET_SIZE]\n",
    "\n",
    "# Compile them into the expected format for the AttackModelBundle.\n",
    "attack_test_data, real_membership_labels = prepare_attack_data(\n",
    "    target_model, data_in, data_out\n",
    ")\n",
    "\n",
    "# Compute the attack accuracy.\n",
    "attack_guesses = amb.predict(attack_test_data)\n",
    "attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n",
    "\n",
    "print (attack_accuracy)\n",
    "print (classification_report(real_membership_labels, attack_guesses))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Custom Federated Algorithms, Part 2: Implementing Federated Averaging",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
