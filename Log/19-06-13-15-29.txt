Train size: 38250, learning rate: 0.0001, num_epochs: 1500, minibatch_size: 32
[0.9451023934276538, 0.8977397872314298, 0.8839655281609572, 0.8763490341198505, 0.8691442055183461, 0.8626293634769805, 0.8569908163537555, 0.8506418274037523, 0.8450329281296176, 0.8399367965414938, 0.835131764511684, 0.8302798118052622, 0.8253970579123393, 0.8210088638830385, 0.8177581533228513, 0.813692607191316, 0.8099598387794014, 0.8060492636269607, 0.8029978172549641, 0.7986606362474509, 0.7963606130627902, 0.7936689456636427, 0.7892627206307581, 0.7861713983773186, 0.7836198975600953, 0.7808360544458088, 0.7770948859937007, 0.7751687838193263, 0.7715786807207876, 0.7684619761660498, 0.7660770731241643, 0.7637320403025246, 0.7610292236924664, 0.758247333241308, 0.7568819085673798, 0.7539453466068246, 0.7513575619234697, 0.748728255123275, 0.7473324891912388, 0.7445560108168848, 0.7433208360831616, 0.740597637901745, 0.7382213372316312, 0.73696771453614, 0.734176915958834, 0.7328189679020126, 0.730626220034756, 0.729460549279737, 0.7273401812030683, 0.7256019434170753, 0.7237752891983453, 0.7216983194630515, 0.720480685154264, 0.7186481930471367, 0.7169577655682509, 0.7156320864685408, 0.7141257610281145, 0.7125063001111956, 0.7115839065617596, 0.7094411444464479, 0.7088520247816541, 0.7085450466207882, 0.706180462652669, 0.704840444520927, 0.7027031495481355, 0.7010726400249683, 0.6998840694148175, 0.698814918057191, 0.697162055620089, 0.6973670405074633, 0.695475724750982, 0.693665394548592, 0.6927631672206793, 0.691353330128363, 0.6901394385423617, 0.6891108561509832, 0.6874586043497511, 0.6869771862379184, 0.6854529065567077, 0.6832581938560045, 0.6831909092899159, 0.6822174094212115, 0.6815339976274832, 0.6801403348166568, 0.678814919997459, 0.6783036147450798, 0.6773625718250434, 0.6756942074667961, 0.6738846255645596, 0.6734586625917185, 0.6718175812495807, 0.6721358504255448, 0.6706756771358986, 0.6706363271719238, 0.6696832751878641, 0.6688205090776156, 0.6664487352181672, 0.6656280019293271, 0.6656816178784712, 0.665767529743984, 0.6635282283298145, 0.6620840327011485, 0.6614985087426635, 0.6613455185580945, 0.659842639238765, 0.6578831337236459, 0.6579567652367148, 0.6575193478971338, 0.6563349697629782, 0.6560006920263858, 0.6553325082966476, 0.6547232530107059, 0.6526057893761025, 0.6521664821951965, 0.6524350774836839, 0.6509865500438169, 0.6517460503588153, 0.6492936935384898, 0.6486780024971421, 0.6489383053829472, 0.6472530558518288, 0.6470067813306674, 0.6451253517402262, 0.6444989973281715, 0.6453676558688104, 0.6445222476037482, 0.6433015442792344, 0.6417372890970205, 0.6412829604108968, 0.6415712076749774, 0.6392121960927256, 0.6403357578870141, 0.6393160550913549, 0.6389942213830586, 0.638685142370447, 0.6369325835086312, 0.6355066626141762, 0.6368361051860717, 0.6373512129653941, 0.6351441125490683, 0.6361494720231534, 0.6340463339783664, 0.6324681844172617, 0.6321776085817675, 0.6317319898425777, 0.6307086859537478, 0.6301112157280958, 0.6297978556056406, 0.6305061595459864, 0.6291275178288817, 0.627094585326926, 0.6279417771674592, 0.6268399485983122, 0.6260578604672254, 0.6261862879018907, 0.624614028875796, 0.6246408873023345, 0.6239685420211886, 0.6232873550518784, 0.6233463651216183, 0.6227694382228607, 0.6224539966762808, 0.6212941815164797, 0.6211627009772863, 0.6199160003013692, 0.6208988690725434, 0.6208373710949555, 0.619796481142483, 0.6177649744634357, 0.6191282718002045, 0.6181735380174722, 0.6172607459533163, 0.6179438828923218, 0.6158238733413334, 0.6167943176365293, 0.61537912083969, 0.6155569234403103, 0.613936564139243, 0.614233427741039, 0.6138950608764226, 0.6140518641621501, 0.6133385560003785, 0.612124042331425, 0.6109743733036958, 0.6122450159932773, 0.6116425201483836, 0.610782066349205, 0.6105719310469208, 0.6095498393270259, 0.6091437188651271, 0.6088856480111635, 0.6082283525037966, 0.6081551043807724, 0.6073180671765714, 0.6077564973711462, 0.6079318451831532, 0.6066190050486239, 0.6051742566180532, 0.6062284490304006, 0.6047745142771117, 0.6054425869776112, 0.6047843561511655, 0.6063206893006131, 0.6037749857583302, 0.6035077937352603, 0.604399750472112, 0.6031597611046227, 0.6023111450871665, 0.6017802597588569, 0.601700491536112, 0.6027361232865306, 0.6007344825746632, 0.6001587856888267, 0.5985668398845148, 0.6000500823413978, 0.6002224576772506, 0.6000283690177243, 0.6000461169865348, 0.598406065258521, 0.5988267549660415, 0.5983870785854848, 0.598132932460458, 0.5967778482447115, 0.5961979173965529, 0.598211498489939, 0.5981426461221783, 0.5952133062993143, 0.5941878641749024, 0.5948930923908827, 0.5944605318572233, 0.5942537838195662, 0.5941724175938005, 0.5951730314657777, 0.593698245760787, 0.5928928188948448, 0.5919797100282619, 0.5923221936285735, 0.5914958057917313, 0.5921876059167057, 0.5911309818593025, 0.5904007841353647, 0.5904292519870658, 0.5899769155674902, 0.5903073383425061, 0.5906003822093224, 0.590791094427826, 0.5896487137513167, 0.5877669292763187, 0.5882988822510058, 0.5878061845960978, 0.5871047176576564, 0.5875435153061386, 0.5884866295000497, 0.5876012850506038, 0.586771790552339, 0.5874034345898167, 0.5861559266201118, 0.586521880272542, 0.586110028861457, 0.5858315383540038, 0.5861004579765534, 0.5849383239716169, 0.5842845969619106, 0.584728722692035, 0.5844822703295668, 0.583123655648412, 0.5828352421646839, 0.582911945162458, 0.5833230545331248, 0.5832180856162038, 0.5829269254556766, 0.5827328240023499, 0.5821114218135258, 0.5839274963325038, 0.5810204083201272, 0.5813579162793171, 0.5809330845228291, 0.5813002420269794, 0.580321805285111, 0.5818800866354459, 0.5806889891873841, 0.5788272708779105, 0.5798641160941013, 0.578732548822419, 0.5777075056002214, 0.5790849606861143, 0.5789853910521986, 0.5772847118487422, 0.5780897765977618, 0.5763472973053428, 0.5775150736256128, 0.576480456051966, 0.5763731054182333, 0.5768589186369113, 0.5757841731090423, 0.5753851279803397, 0.5746512388085722, 0.5746491060845517, 0.5762856089420396, 0.5754999445821448]
Train Accuracy: 0.7614118
Test Accuracy: 0.50251853
